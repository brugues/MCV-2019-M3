{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Students**: Sergio Casas Pastor, Sanket Biswas and Josep Brugués i Pujolràs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST CODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cPickle\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import time\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first read the train and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_images_filenames = cPickle.load(open('train_images_filenames.dat','r'))\n",
    "test_images_filenames = cPickle.load(open('test_images_filenames.dat','r'))\n",
    "train_labels = cPickle.load(open('train_labels.dat','r'))\n",
    "test_labels = cPickle.load(open('test_labels.dat','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../Databases/MIT_split/train/Opencountry/fie26.jpg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_filenames[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a SIFT object detector and descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "SIFTdetector = cv2.xfeatures2d.SIFT_create(nfeatures=900)\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute different spatial pyramid level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "level = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the SIFT descriptors for all the train images and subsequently build a numpy array with all the descriptors stacked together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Train_descriptors = []\n",
    "Train_label_per_descriptor = []\n",
    "\n",
    "for filename,labels in zip(train_images_filenames,train_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    step = 10 # Separation of 10 pixels between keypoints\n",
    "    keypoints = []\n",
    "    \n",
    "    for i in range(step/2, ima.shape[0], step):\n",
    "        #print(i)\n",
    "        for j in range(step/2, ima.shape[1], step):             \n",
    "            #print(j)\n",
    "            keypoints.append(cv2.KeyPoint(i, j, step))\n",
    "     \n",
    "    # Compute spatial pyramids\n",
    "    height_block = int(np.ceil(ima.shape[0] / level))  # Number of height pixels for sub-image\n",
    "    width_block = int(np.ceil(ima.shape[1] / level))    # Number of width pixels for sub-image\n",
    "    \n",
    "    \n",
    "    for i in range(0, ima.shape[0], height_block):\n",
    "        for j in range(0, ima.shape[1], width_block):\n",
    "            block = gray[i:i + height_block, j:j + width_block]\n",
    "            \n",
    "            _, descriptors = SIFTdetector.compute(block,keypoints)\n",
    "    \n",
    "            Train_descriptors.append(descriptors)\n",
    "            Train_label_per_descriptor.append(labels)\n",
    "\n",
    "D=np.vstack(Train_descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute a k-means clustering on the descriptor space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "k = 170\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "codebook.fit(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, for each train image, we project each keypoint descriptor to its closest visual word. We represent each of the images with the frequency of each visual word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "visual_words=np.zeros((len(Train_descriptors),k),dtype=np.float32)\n",
    "for i in xrange(len(Train_descriptors)):\n",
    "    words=codebook.predict(Train_descriptors[i])\n",
    "    visual_words[i,:]=np.bincount(words,minlength=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a k-nn classifier and train it with the train descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10,n_jobs=-1,metric='euclidean')\n",
    "knn.fit(visual_words, Train_label_per_descriptor) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up computing the test descriptors and compute the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "for image in range(len(test_images_filenames)):\n",
    "    filename=test_images_filenames[image]\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    keypoints_test = []\n",
    "    \n",
    "    for i in range(step/2, ima.shape[0], step):\n",
    "        for j in range(step/2, ima.shape[1], step):             \n",
    "            keypoints_test.append(cv2.KeyPoint(i, j, step))\n",
    "     \n",
    "    # Compute spatial pyramids\n",
    "    height_block = int(np.ceil(ima.shape[0] / level))  # Number of height pixels for sub-image\n",
    "    width_block = int(np.ceil(ima.shape[1] / level))    # Number of width pixels for sub-image\n",
    "    for i in range(0, ima.shape[0], height_block):\n",
    "        for j in range(0, ima.shape[1], width_block):\n",
    "            block = gray[i:i + height_block, j:j + width_block]\n",
    "            \n",
    "            _, descriptors_test = SIFTdetector.compute(block,keypoints)\n",
    "            \n",
    "            words=codebook.predict(descriptors_test)\n",
    "            visual_words_test[image,:]=np.bincount(words,minlength=k)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "accuracy = 100*knn.score(visual_words_test, test_labels)\n",
    "print(accuracy)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction, with PCA and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.96034696406444\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=64)\n",
    "VWpca = pca.fit_transform(visual_words)\n",
    "knnpca = KNeighborsClassifier(n_neighbors=10,n_jobs=-1,metric='euclidean')\n",
    "knnpca.fit(VWpca, train_labels) \n",
    "vwtestpca = pca.transform(visual_words_test)\n",
    "accuracy = 100*knnpca.score(vwtestpca, test_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sergio\\desktop\\machine learning for cv\\project\\mcv-2019-m3\\venv\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.66047087980174\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=64)\n",
    "VWlda = lda.fit_transform(visual_words,train_labels)\n",
    "knnlda = KNeighborsClassifier(n_neighbors=10,n_jobs=-1,metric='euclidean')\n",
    "knnlda.fit(VWlda, train_labels) \n",
    "vwtestlda = lda.transform(visual_words_test)\n",
    "accuracy = 100*knnlda.score(vwtestlda, test_labels)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESULTS AND DISCUSSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test different amount of local features.\n",
    "We keep the rest of the parameters with initial values (SIFT, Codebook size k = 128, neighbours k = 5, euclidean distance, no reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "number = [10, 100, 150, 200, 250, 300, 350, 400, 500, 600, 700, 800, 850, 900, 950, 1000, 1200, 1400]\n",
    "accuracy = [22.18, 39.03, 47.21, 52.42, 53.53, 52.42, 55.64, 57.5, 54.77, 58.24, 56.88, 58.11, 57.74, 61.34, 57.49, 58.99, 58.36, 58.49]\n",
    "plt.scatter(number, accuracy)\n",
    "plt.plot(number[13], accuracy[13], 'g*')\n",
    "plt.ylim((0, 100))\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "ymax = max(accuracy)\n",
    "xpos = accuracy.index(ymax)\n",
    "xmax = number[xpos]\n",
    "plt.annotate('   local max', xy=(xmax, ymax), xytext=(xmax, ymax+5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "time = [53, 53, 53, 54, 57, 57, 59, 61, 63, 63, 63, 64, 64, 64, 65, 65, 63, 63]\n",
    "plt.scatter(number, time)\n",
    "plt.ylim((0, 70))\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"Computation time (s)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the maximum accuracy with 900 features. The computation time is very similar using different number of features. Therefore, we conclude that, using SIFT feature detector, Codebook size 128, 5 k-nn neighbours, euclidean distance and no reduction, the best performance is with approximate 900 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use dense SIFT instead of detected keypoints. This way, the detected keypoints are equally distributed in the image and not only in the interesting points. There is a parameter (step size) we can vary to create different distributions. We again keep the rest of the parameters like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "filename=train_images_filenames[1]\n",
    "ima=cv2.imread(filename)\n",
    "gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "step = 10\n",
    "kpt = []\n",
    "    \n",
    "for i in xrange(step/2, ima.shape[0], step):\n",
    "    for j in xrange(step/2, ima.shape[1], step):\n",
    "        kpt.append(cv2.KeyPoint(i, j, step))\n",
    "     \n",
    "kpt,des=SIFTdetector.compute(gray,kpt)\n",
    "\n",
    "keypointsIma = ima\n",
    "keypointsIma = cv2.drawKeypoints(ima, kpt, keypointsIma)\n",
    "plt.imshow(keypointsIma)\n",
    "plt.title('Image with dense keypoints')\n",
    "plt.show()\n",
    "print(\"Example of dense SIFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "step = [5, 10, 15, 20, 40, 60, 100]\n",
    "accuracy = [9.91, 9.91, 9.91, 9.91, 14.62, 14.62, 11.64]\n",
    "plt.scatter(step, accuracy)\n",
    "plt.ylim((0, 100))\n",
    "plt.xlabel(\"Step size\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense SIFT keypoint detector produces much worse results than normal SIFT keypoint detector because the keypoints are not only in the interesting regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the best number of features found, and without using dense SIFT, we then find which is the best number of codewords for the k-means. We first iterate over the powers of 2. Once the best two values were found, we precise the k parameter a little bit more just to get the best result possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "k = [2,4,8,16,32,64,128,140,160,165,170,175,180,200,256,512]\n",
    "accuracy = [30.23,39.28,41.14,46.71,52.91,56.75,56.87,57.62,59.1,58.48,60.71,57.74,58.98, 57.24,57.74,52.91]\n",
    "pca_accuracy = [0,0,0,0,0,56.75,59.23,59.47,60.22,59.72,60.09,57.12,61.71,59.6,61.58,61.09]\n",
    "lda_accuracy = [0,0,0,0,0,63.19,61.71,61.21,66.17,65.03,63.94,65.67,64.93,65.92,63.81,59.1]\n",
    "\n",
    "plt.scatter(k, accuracy)\n",
    "plt.ylim((0, 100))\n",
    "plt.xlabel(\"Step size\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "ymax = max(accuracy)\n",
    "xpos = accuracy.index(ymax)\n",
    "xmax = k[xpos]\n",
    "plt.annotate('   local max', xy=(xmax, ymax), xytext=(xmax, ymax+5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),)\n",
    "plt.show()\n",
    "print \"Local max is\", ymax,\"% accuracy at k=\",xmax\n",
    "\n",
    "plt.scatter(k, pca_accuracy)\n",
    "plt.ylim((0, 100))\n",
    "plt.xlabel(\"Step size\")\n",
    "plt.ylabel(\"PCA Accuracy (%)\")\n",
    "ymax = max(pca_accuracy)\n",
    "xpos = pca_accuracy.index(ymax)\n",
    "xmax = k[xpos]\n",
    "plt.annotate('   local max', xy=(xmax, ymax), xytext=(xmax, ymax+5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),)\n",
    "plt.show()\n",
    "print \"Local max is\", ymax,\"% PCA accuracy at k=\",xmax\n",
    "\n",
    "\n",
    "plt.scatter(k, lda_accuracy)\n",
    "plt.ylim((0, 100))\n",
    "plt.xlabel(\"Step size\")\n",
    "plt.ylabel(\"LDA Accuracy (%)\")\n",
    "ymax = max(lda_accuracy)\n",
    "xpos = lda_accuracy.index(ymax)\n",
    "xmax = k[xpos]\n",
    "plt.annotate('    local max', xy=(xmax, ymax), xytext=(xmax, ymax+5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),)\n",
    "\n",
    "plt.show()\n",
    "print \"Local max is\", ymax,\"% LDA accuracy at k=\",xmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, we think that k=170 is the best option since it gets the best accuracy without applying any feature reduction algorithm. If we look at the computational time, there is almost no overhead added with different changes in the K value (if we take into account that a slower processor than before has been used). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "k = [2,4,8,16,32,64,128,140,160,165,170,175,180,200,256,512]\n",
    "time = [100,83,78,76,74,75,86,79,78,95,91,82,89,83,87,108]\n",
    "plt.scatter(k, time)\n",
    "plt.ylim((0, 120))\n",
    "plt.xlabel(\"Number of codewords (K)\")\n",
    "plt.ylabel(\"Computation time (s)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the best number of codewords was established, we look to optimize the number of neighbours taken into account by the K-NN classifier. We use the best number of features (900) and the best number of codewords (170), leaving the rest of parameters as default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "k = [1,2,3,4,5,6,7,8,9,10,15,20,21,22,23,24,25,30]\n",
    "accuracy = [55.63,53.4,57.99,57.86,60.71,60.47,60.96,61.83,60.71,60.96,62.08,62.94,62.57,61.46,61.46,61.95,62.20,60.47]\n",
    "pca_accuracy = [56.01,54.27,57.62,60.71,61.33,61.71,62.94,63.19,64.18,63.32,63.81,63.32,62.45,62.57,62.70,62.57,62.08,62.20]\n",
    "lda_accuracy = [59.1,57.62,61.71,63.56,65.67,64.68,66.17,65.42,65.17,66.17,66.29,65.79,65.92,65.79,66.17,66.41,66.17,66.04]\n",
    "\n",
    "plt.scatter(k, accuracy)\n",
    "plt.ylim((0, 100))\n",
    "plt.xlabel(\"Step size\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "ymax = max(accuracy)\n",
    "xpos = accuracy.index(ymax)\n",
    "xmax = k[xpos]\n",
    "plt.annotate('   local max', xy=(xmax, ymax), xytext=(xmax, ymax+5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),)\n",
    "plt.show()\n",
    "print \"Local max is\", ymax,\"% accuracy at k=\",xmax\n",
    "\n",
    "plt.scatter(k, pca_accuracy)\n",
    "plt.ylim((0, 100))\n",
    "plt.xlabel(\"Step size\")\n",
    "plt.ylabel(\"PCA Accuracy (%)\")\n",
    "ymax = max(pca_accuracy)\n",
    "xpos = pca_accuracy.index(ymax)\n",
    "xmax = k[xpos]\n",
    "plt.annotate('   local max', xy=(xmax, ymax), xytext=(xmax, ymax+5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),)\n",
    "plt.show()\n",
    "print \"Local max is\", ymax,\"% PCA accuracy at k=\",xmax\n",
    "\n",
    "\n",
    "plt.scatter(k, lda_accuracy)\n",
    "plt.ylim((0, 100))\n",
    "plt.xlabel(\"Step size\")\n",
    "plt.ylabel(\"LDA Accuracy (%)\")\n",
    "ymax = max(lda_accuracy)\n",
    "xpos = lda_accuracy.index(ymax)\n",
    "xmax = k[xpos]\n",
    "plt.annotate('    local max', xy=(xmax, ymax), xytext=(xmax, ymax+5),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),)\n",
    "\n",
    "plt.show()\n",
    "print \"Local max is\", ymax,\"% LDA accuracy at k=\",xmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results just presented, we think that looking at k=20 neighbours is the best option, since it has the best accuracy without reducing the number of features and, when reducing features, it does not lose much accuracy with respect to the best PCA and LDA results. Despite that, the improvement is not big, taking into account the results obtained before when analysing the number of features and the number of codewords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we test different distances for the k-NN algorithm, to see which one was the best suited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "distances = [\"euclidean\",\"minkowski\", \"manhattan\", \"chebyshev\"]\n",
    "accuracy = [62.94,62.94,56.75,52.29]\n",
    "pca_accuracy = [63.32,63.32,58.36,59.85]\n",
    "lda_accuracy = [65.79,65.79,66.54,64.31]\n",
    "\n",
    "plt.scatter(distances, accuracy)\n",
    "plt.ylim((0, 100))\n",
    "plt.xlabel(\"Step size\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "ymax = max(accuracy)\n",
    "xpos = accuracy.index(ymax)\n",
    "xmax = k[xpos]\n",
    "plt.show()\n",
    "print \"Local max is\", ymax,\"% accuracy\"\n",
    "\n",
    "plt.scatter(distances, pca_accuracy)\n",
    "plt.ylim((0, 100))\n",
    "plt.xlabel(\"Step size\")\n",
    "plt.ylabel(\"PCA Accuracy (%)\")\n",
    "ymax = max(pca_accuracy)\n",
    "xpos = pca_accuracy.index(ymax)\n",
    "xmax = k[xpos]\n",
    "plt.show()\n",
    "print \"Local max is\", ymax,\"% PCA accuracy\"\n",
    "\n",
    "\n",
    "plt.scatter(distances, lda_accuracy)\n",
    "plt.ylim((0, 100))\n",
    "plt.xlabel(\"Step size\")\n",
    "plt.ylabel(\"LDA Accuracy (%)\")\n",
    "ymax = max(lda_accuracy)\n",
    "xpos = lda_accuracy.index(ymax)\n",
    "xmax = k[xpos]\n",
    "plt.show()\n",
    "print \"Local max is\", ymax,\"% LDA accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plots above, the best performing distance is the euclidean (when not performing any kind of feature reduction). That means that using other distances does not make any difference. \n",
    "Minkowski distance is the generalization of the rest of the distances. It contains a parameter p. When p = 1, minkowski distance is manhattan; when p = 2, minkowski distance is euclidean; and when p = infinity, minkowski distance is chebyshev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print \"Representation of some points using different distances\"\n",
    "x = [0, 1, 0.5, 0, -0.5, -1, -0.5, 0, 0.5]\n",
    "manhattan = [0, 0, 0.5, 1, 0.5, 0, -0.5, -1, -0.5]\n",
    "euclidean = [0, 0, 0.71, 1, 0.71, 0, -0.71, -1, -0.71]\n",
    "chebyshev = [0, 0, 1, 1, 1, 0, -1, -1, -1]\n",
    "\n",
    "plt.scatter(x, manhattan)\n",
    "plt.ylim((-1, 1))\n",
    "plt.xlim((-1, 1))\n",
    "plt.xlabel(\"Manhattan distance (minkowski p = 1)\")\n",
    "plt.plot(x[0], manhattan[0], 'r*')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(x, euclidean)\n",
    "plt.ylim((-1, 1))\n",
    "plt.xlim((-1, 1))\n",
    "plt.xlabel(\"Euclidean distance (minkowski p = 2)\")\n",
    "plt.plot(x[0], manhattan[0], 'r*')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x, chebyshev)\n",
    "plt.ylim((-1, 1))\n",
    "plt.xlim((-1, 1))\n",
    "plt.xlabel(\"Chebyshev distance (minkowski p = infinity)\")\n",
    "plt.plot(x[0], chebyshev[0], 'r*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our test, we use minkowski p = 2, so it is the same as euclidean distance. That is why minkowski distance accuracy is the same as euclidean distance. \n",
    "\n",
    "The reason why euclidean distance is the best is because the distance in all directions is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "**Conclusions**\n",
    "\n",
    "Dimensionality reduction actually has helped to improve the classification accuracy as shown in our experiments. PCA and LDA for reducing dimensionality of computed features has helped to increase accuracy in most cases. This is because it takes the most important features into the global feature representation vector before finally classifying the features with the K-Nearest Neighbours algorithm with the different distance metrics applied. The redundant features are taken out and hence this optimizes the computation time as well as improvises the model accuracy for classification.  \n",
    "\n",
    "Comparing between LDA and PCA, LDA with k-Nearest Neighbors classifier gives us better results than PCA because it also takes the class labels, unlike PCA, helps to calculate the max separation between mean of the projected classes and chooses the dimension with minimum variance among them. The discriminatory information mostly lies in the mean and hence we get more improved results than PCA as shown in the visualizations of results and experiments.       \n",
    "\n",
    "Finally, the classification task may be improved by experimenting with classifier algorihms like Support Vector Machines or Random Forests, in place of K-Nearest Neighbours which we used in this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
